{
 "cells": [
  {
   "cell_type": "raw",
   "id": "9ca11673",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.005265,
     "end_time": "2025-03-19T18:32:29.050089",
     "exception": false,
     "start_time": "2025-03-19T18:32:29.044824",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a672c615",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T18:32:29.061372Z",
     "iopub.status.busy": "2025-03-19T18:32:29.060830Z",
     "iopub.status.idle": "2025-03-19T18:32:49.021320Z",
     "shell.execute_reply": "2025-03-19T18:32:49.020240Z"
    },
    "papermill": {
     "duration": 19.968225,
     "end_time": "2025-03-19T18:32:49.023227",
     "exception": false,
     "start_time": "2025-03-19T18:32:29.055002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d43903",
   "metadata": {
    "papermill": {
     "duration": 0.004292,
     "end_time": "2025-03-19T18:32:49.032525",
     "exception": false,
     "start_time": "2025-03-19T18:32:49.028233",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We need data set to handle / train / test our data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdfcdf78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T18:32:49.044209Z",
     "iopub.status.busy": "2025-03-19T18:32:49.043473Z",
     "iopub.status.idle": "2025-03-19T18:32:49.130890Z",
     "shell.execute_reply": "2025-03-19T18:32:49.129647Z"
    },
    "papermill": {
     "duration": 0.095373,
     "end_time": "2025-03-19T18:32:49.133015",
     "exception": false,
     "start_time": "2025-03-19T18:32:49.037642",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65444465",
   "metadata": {
    "papermill": {
     "duration": 0.004274,
     "end_time": "2025-03-19T18:32:49.142028",
     "exception": false,
     "start_time": "2025-03-19T18:32:49.137754",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "So far so good what about the data present in it \\n if you load all the data then what will you test with you don't have a personal ai to synthazie the data for you but you can split the data if you want to 80% can be used to train the data and 20% can be used to test the data to adjut is underfitting or overfitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f1e21ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T18:32:49.152234Z",
     "iopub.status.busy": "2025-03-19T18:32:49.151835Z",
     "iopub.status.idle": "2025-03-19T18:32:50.548350Z",
     "shell.execute_reply": "2025-03-19T18:32:50.547148Z"
    },
    "papermill": {
     "duration": 1.40399,
     "end_time": "2025-03-19T18:32:50.550522",
     "exception": false,
     "start_time": "2025-03-19T18:32:49.146532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train,y_train),(x_test,y_test)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ddf741",
   "metadata": {
    "papermill": {
     "duration": 0.005763,
     "end_time": "2025-03-19T18:32:50.562291",
     "exception": false,
     "start_time": "2025-03-19T18:32:50.556528",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Alright Genius the data is been loaded into the system as needed and splitted as needed but if you want to makesure that all of the data is in the same level and same kind and size we need to normalize it but why ? is our model is soo weak it can't handle the data in real time by sending it to the appropiate functions -> May be but it's not neccessary now like imagine if you are going to mcdonalds you don't want one fry to super microscopic and other to be gigantic it doesn't happend that way why -> the cooking apparatus and procedure and everything is based on a specific calulation that requires exact metrics to give optimal result in mass that's what happeing here as well think it of as we are brining all the potatoes of the same kind and size to get optimal result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fc753c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T18:32:50.575284Z",
     "iopub.status.busy": "2025-03-19T18:32:50.574872Z",
     "iopub.status.idle": "2025-03-19T18:32:51.231537Z",
     "shell.execute_reply": "2025-03-19T18:32:51.230504Z"
    },
    "papermill": {
     "duration": 0.665227,
     "end_time": "2025-03-19T18:32:51.233580",
     "exception": false,
     "start_time": "2025-03-19T18:32:50.568353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "(x_train),(x_test)=(x_train/255.0),(x_test/255.0)\n",
    "# ONE WAY SIMPLE to put pixel from 0 or 1 rather than between 0-255\n",
    "x_train=tf.keras.utils.normalize(x_train,axis=1)\n",
    "# y_train=tf.keras.utils.normalize(y_train,axis=1)\n",
    "x_test=tf.keras.utils.normalize(x_test,axis=1)\n",
    "# y_test=tf.keras.utils.normalize(y_test,axis=1)\n",
    "#Other way hardway but most widely used lol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b4bbe0",
   "metadata": {
    "papermill": {
     "duration": 0.006148,
     "end_time": "2025-03-19T18:32:51.248405",
     "exception": false,
     "start_time": "2025-03-19T18:32:51.242257",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Mistakes made : 1. I normalized the y_test/y_train that's just a label but i failed to recoginize "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf0360e",
   "metadata": {
    "papermill": {
     "duration": 0.005625,
     "end_time": "2025-03-19T18:32:51.259622",
     "exception": false,
     "start_time": "2025-03-19T18:32:51.253997",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**SO far we have prepared the data for the process like normalizing it and allowing to be used by the model**\n",
    "\n",
    "What's next -> when data is ready what we can do is to use it in a model to get insights so that we can predict something from those insights and pattern recogniztion,\n",
    "\n",
    "So, Let's pickup the model -> where exactly the mighty model is present as a fact of commonsense is we are using the simple neural networks to clssify the images so for which we are using the Tensor Flow in which we have keras framwork and with in that we have some models under model as of now we are going to use sequential but why?\n",
    "\n",
    "For single input and output sequential will be the best but multi input and outputs the RNN's CNN's are the best.\n",
    "\n",
    "so in short \n",
    "\n",
    "tensorflow -> keras -> models -> sequential "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cef5f4d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T18:32:51.272034Z",
     "iopub.status.busy": "2025-03-19T18:32:51.271682Z",
     "iopub.status.idle": "2025-03-19T18:32:51.277826Z",
     "shell.execute_reply": "2025-03-19T18:32:51.276800Z"
    },
    "papermill": {
     "duration": 0.014357,
     "end_time": "2025-03-19T18:32:51.279520",
     "exception": false,
     "start_time": "2025-03-19T18:32:51.265163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21911b55",
   "metadata": {
    "papermill": {
     "duration": 0.005132,
     "end_time": "2025-03-19T18:32:51.290652",
     "exception": false,
     "start_time": "2025-03-19T18:32:51.285520",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "When sucessfully adding the model then what's next \n",
    "\n",
    "Ok you added model so is that mean you purchased a ferrari and let's drive to japan on the water it doesn't work that way,\n",
    "\n",
    "right now you have purchased the ingridents what's neccessary to make a chicken curry now what's the main ingrident it's chicken genius \n",
    "\n",
    "so, we got the model so what's next \n",
    "\n",
    "understand what are needed in this model \n",
    "\n",
    "genrally a model has layers to it input / Hidden / Output layer \n",
    "\n",
    "\n",
    "** NOW LET'S KEEP EVERYTHING INTO ONE BIG LONG 1D VECTOR FROM MULTI DEMENSIONAL LIKE 5X5 WILL BE CONVERTED INTO ONE BIG 25 PIXEL LONG VECTOR ** -> WHY DO WE NEED TO DO THIS ?\n",
    "\n",
    "-> Cosnider we are having a 2d structure and we cannot really feed that to the dense layer as it accepts only 1d as a input so we have to convert it into a single 1 d structure to feed into it if we feed 2d LOL get ready for a error you will never understand so convert to 1d \n",
    "\n",
    "SO How it is done  consider a cube if you convert it to a 1d structure if will be flat as earth so the term we use is flatten \n",
    "\n",
    "tf.keras.models.sequential -> model.add(tf.keras.layers.Flatten(input_shape=(28,28))\n",
    "\n",
    "as we are adding it to the model we use model.add()\n",
    "\n",
    "i got a starnge question what is happening under the scenes before the passing of the data into the flatten layer \n",
    "\n",
    "1. The data will be going through the convolution and pooling layers for feature extraction\n",
    "2. Now we need to do classification for which we need to feed the data into the all mighty DENSE layer tah tah tah.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f435236",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T18:32:51.303066Z",
     "iopub.status.busy": "2025-03-19T18:32:51.302662Z",
     "iopub.status.idle": "2025-03-19T18:32:51.314305Z",
     "shell.execute_reply": "2025-03-19T18:32:51.313071Z"
    },
    "papermill": {
     "duration": 0.019887,
     "end_time": "2025-03-19T18:32:51.316047",
     "exception": false,
     "start_time": "2025-03-19T18:32:51.296160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model.add(tf.keras.layers.Flatten(input_shape=(28,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3d1d989",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T18:32:51.329075Z",
     "iopub.status.busy": "2025-03-19T18:32:51.328729Z",
     "iopub.status.idle": "2025-03-19T18:32:51.418315Z",
     "shell.execute_reply": "2025-03-19T18:32:51.417066Z"
    },
    "papermill": {
     "duration": 0.098263,
     "end_time": "2025-03-19T18:32:51.420370",
     "exception": false,
     "start_time": "2025-03-19T18:32:51.322107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(128,activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(128,activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36970f9",
   "metadata": {
    "papermill": {
     "duration": 0.005467,
     "end_time": "2025-03-19T18:32:51.431911",
     "exception": false,
     "start_time": "2025-03-19T18:32:51.426444",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now let's do output layer which is all the same but it needs only uses the activation as 'softmax'Softmax converts these raw numbers into percentages (probabilities).\n",
    "now we have 10 possible outputs we would have 10 neurons at the  output layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1803e205",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T18:32:51.444816Z",
     "iopub.status.busy": "2025-03-19T18:32:51.444481Z",
     "iopub.status.idle": "2025-03-19T18:32:51.463197Z",
     "shell.execute_reply": "2025-03-19T18:32:51.461902Z"
    },
    "papermill": {
     "duration": 0.027504,
     "end_time": "2025-03-19T18:32:51.465199",
     "exception": false,
     "start_time": "2025-03-19T18:32:51.437695",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96237e04",
   "metadata": {
    "papermill": {
     "duration": 0.005388,
     "end_time": "2025-03-19T18:32:51.476405",
     "exception": false,
     "start_time": "2025-03-19T18:32:51.471017",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bb84889",
   "metadata": {
    "papermill": {
     "duration": 0.005286,
     "end_time": "2025-03-19T18:32:51.487274",
     "exception": false,
     "start_time": "2025-03-19T18:32:51.481988",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In machine learning, especially deep learning, Optimizers and Loss Functions are essential for training a model.\n",
    "\tâ€¢\tLoss Function: Measures how bad the modelâ€™s predictions are. It tells us how far off we are from the correct answer.\n",
    "\tâ€¢\tOptimizer Function: Adjusts the modelâ€™s parameters (weights and biases) to minimize the loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46f4a12",
   "metadata": {
    "papermill": {
     "duration": 0.005289,
     "end_time": "2025-03-19T18:32:51.498236",
     "exception": false,
     "start_time": "2025-03-19T18:32:51.492947",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Metrics in machine learning evaluate the performance of a model during training and testing. While the loss function guides the optimization process, metrics help track how well the model is performing.\n",
    "\n",
    "Think of metrics like a scoreboard in a game ğŸ®:\n",
    "\tâ€¢\tThe loss function is like the coachâ€™s feedback on mistakes.\n",
    "\tâ€¢\tMetrics are like the scoreboard, showing how well youâ€™re playing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ab31b40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T18:32:51.510860Z",
     "iopub.status.busy": "2025-03-19T18:32:51.510458Z",
     "iopub.status.idle": "2025-03-19T18:32:51.525836Z",
     "shell.execute_reply": "2025-03-19T18:32:51.524865Z"
    },
    "papermill": {
     "duration": 0.02396,
     "end_time": "2025-03-19T18:32:51.527768",
     "exception": false,
     "start_time": "2025-03-19T18:32:51.503808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbdd9409",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T18:32:51.541427Z",
     "iopub.status.busy": "2025-03-19T18:32:51.541007Z",
     "iopub.status.idle": "2025-03-19T18:34:10.253339Z",
     "shell.execute_reply": "2025-03-19T18:34:10.252054Z"
    },
    "papermill": {
     "duration": 78.721885,
     "end_time": "2025-03-19T18:34:10.255453",
     "exception": false,
     "start_time": "2025-03-19T18:32:51.533568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/13\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8625 - loss: 0.4767\n",
      "Epoch 2/13\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9645 - loss: 0.1140\n",
      "Epoch 3/13\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9767 - loss: 0.0746\n",
      "Epoch 4/13\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9835 - loss: 0.0519\n",
      "Epoch 5/13\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9885 - loss: 0.0359\n",
      "Epoch 6/13\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9906 - loss: 0.0298\n",
      "Epoch 7/13\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9925 - loss: 0.0230\n",
      "Epoch 8/13\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9935 - loss: 0.0189\n",
      "Epoch 9/13\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9954 - loss: 0.0145\n",
      "Epoch 10/13\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9941 - loss: 0.0163\n",
      "Epoch 11/13\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9963 - loss: 0.0101\n",
      "Epoch 12/13\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9963 - loss: 0.0108\n",
      "Epoch 13/13\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9972 - loss: 0.0090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7c88848040a0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cc50ac",
   "metadata": {
    "papermill": {
     "duration": 0.093577,
     "end_time": "2025-03-19T18:34:10.442433",
     "exception": false,
     "start_time": "2025-03-19T18:34:10.348856",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c3db842",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T18:34:10.632472Z",
     "iopub.status.busy": "2025-03-19T18:34:10.632043Z",
     "iopub.status.idle": "2025-03-19T18:34:11.394457Z",
     "shell.execute_reply": "2025-03-19T18:34:11.393175Z"
    },
    "papermill": {
     "duration": 0.858436,
     "end_time": "2025-03-19T18:34:11.396450",
     "exception": false,
     "start_time": "2025-03-19T18:34:10.538014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9708 - loss: 0.1473\n",
      "loss =  0.13660269975662231\n",
      "Accuracy =  0.9732999801635742\n"
     ]
    }
   ],
   "source": [
    "# model.save('hw.model')\n",
    "# model=tf.keras.models.load_model('hw.model')\n",
    "\n",
    "loss,accuracy=model.evaluate(x_test,y_test)\n",
    "\n",
    "print('loss = ',loss)\n",
    "print('Accuracy = ',accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f22c88",
   "metadata": {
    "papermill": {
     "duration": 0.155846,
     "end_time": "2025-03-19T18:34:11.646541",
     "exception": false,
     "start_time": "2025-03-19T18:34:11.490695",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "END 14:33"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 107.361816,
   "end_time": "2025-03-19T18:34:13.468398",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-19T18:32:26.106582",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
